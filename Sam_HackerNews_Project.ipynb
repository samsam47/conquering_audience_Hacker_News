{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to conquer audience on a social network tech-oriented ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's study 20,000 different posts from Hacker News to determine what are the keys of a post' success.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hacker News** is a site started by the startup incubator *Y Combinator*, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and discovering the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full dataset is available at [this link](https://www.kaggle.com/hacker-news/hacker-news-posts) on Kaggle platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of the rows of the set to have a better idea on what data we will deal with during this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do that, we'll first write a function named **explore_data()** that we can use repeatedly to explore rows in a more readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(hn,0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will manage the headers properly, in order to have a dataset **full of usable data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = hn[0:1]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's precise that we will specifically be interested in posts whose titles begin with either **Ask HN** or **Show HN**, as these posts are the most relevant for our study.\n",
    "* Users submit **Ask HN** posts to ask the Hacker News community a specific question.\n",
    "* Users submit **Show HN** posts to share a thought or a discovert with the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(ask_posts,0,2)\n",
    "explore_data(show_posts,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis using average and datatime\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore the two lists made respectively with \"show\" and \"ask\" posts. The first (show) contains **1162** rows whereas the second (ask) contains **1744** rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we want to determine what type of posts generates the more reactions from the audience. To evaluate this qualitative effect, we will first explore the relevant quantitative data we have : the number of comments generated by each post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1) First analysis : \"show\" vs \"ask\" posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this analysis, we will use the fifth column : **num_comment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']]\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04\n",
      "10.32\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "    \n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "    \n",
    "average_ask_comments = total_ask_comments / len(ask_posts)\n",
    "average_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(round(average_ask_comments,2))\n",
    "print(round(average_show_comments,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that \"ask posts\" generates more comments than \"show posts\". We can explain that using the idea that people are more likely to answer to a question than reacting to an opinion. Indeed, a question really calls the reader and easily provoke a reaction whereas an opinion is more likely to \"not worth it\" for the reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since ask posts gather the more audience, we will now focus our remaining analysis on these posts. Let's determine if ask posts created at a **certain time** are more likely to attract comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Is there a \"best hour\" to ask-post something ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use datetime class to perform analysis on posts' dates and hours. In order to better understand the arguments of the .strptime method, you can refer to this [site](https://strftime.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    element_1 = row[6] # Let's pick the creating date of the post\n",
    "    element_2 = int(row[4]) # We take also the number of comments of the post\n",
    "    \n",
    "    # We transform the date in a datetime object using .strptime method\n",
    "    # And we join it to the number of comments in the same list\n",
    "    \n",
    "    element_1 = dt.datetime.strptime(element_1, \"%m/%d/%Y %H:%M\")\n",
    "    result_list.append([element_1, element_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created a datetime object, we can perform some analysis on it. We want to know **what time slot** gathers the more ask posts and the more comments in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for join_element in result_list:\n",
    "    element_1 = join_element[0]\n",
    "    hour = element_1.strftime(\"%H\") # We take only the hour from the datetime object\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = join_element[1] # We add the number of comment of the post\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += join_element[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17': 100, '11': 58, '01': 60, '03': 54, '02': 58, '20': 80, '07': 34, '15': 116, '04': 47, '00': 55, '14': 107, '13': 85, '09': 45, '23': 68, '19': 110, '05': 46, '21': 109, '06': 44, '16': 108, '12': 73, '08': 48, '10': 59, '18': 109, '22': 71}\n"
     ]
    }
   ],
   "source": [
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17': 1146, '11': 641, '01': 683, '03': 421, '02': 1381, '20': 1722, '07': 267, '15': 4477, '04': 337, '00': 447, '14': 1416, '13': 1253, '09': 251, '23': 543, '19': 1188, '05': 464, '21': 1745, '06': 397, '16': 1814, '12': 687, '08': 492, '10': 793, '18': 1439, '22': 479}\n"
     ]
    }
   ],
   "source": [
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we created two dictionaries:\n",
    "\n",
    "- **counts_by_hour** : contains the number of ask posts created during each hour of the day.\n",
    "- **comments_by_hour** : contains the corresponding number of comments ask posts created at each hour received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use these two dictionaries to calculate **the average number of comments** for ask-posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['17', 11.46],\n",
       " ['11', 11.052],\n",
       " ['01', 11.383],\n",
       " ['03', 7.796],\n",
       " ['02', 23.81],\n",
       " ['20', 21.525],\n",
       " ['07', 7.853],\n",
       " ['15', 38.595],\n",
       " ['04', 7.17],\n",
       " ['00', 8.127],\n",
       " ['14', 13.234],\n",
       " ['13', 14.741],\n",
       " ['09', 5.578],\n",
       " ['23', 7.985],\n",
       " ['19', 10.8],\n",
       " ['05', 10.087],\n",
       " ['21', 16.009],\n",
       " ['06', 9.023],\n",
       " ['16', 16.796],\n",
       " ['12', 9.411],\n",
       " ['08', 10.25],\n",
       " ['10', 13.441],\n",
       " ['18', 13.202],\n",
       " ['22', 6.746]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    mean = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, round(mean, 3)])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is difficult to read. That's why we will finally sort the list and print the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.46, '17'], [11.052, '11'], [11.383, '01'], [7.796, '03'], [23.81, '02'], [21.525, '20'], [7.853, '07'], [38.595, '15'], [7.17, '04'], [8.127, '00'], [13.234, '14'], [14.741, '13'], [5.578, '09'], [7.985, '23'], [10.8, '19'], [10.087, '05'], [16.009, '21'], [9.023, '06'], [16.796, '16'], [9.411, '12'], [10.25, '08'], [13.441, '10'], [13.202, '18'], [6.746, '22']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "# We first swap both elements of the lists included in avg_by_hour\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\\n\")\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1],\"%H\")\n",
    "    hour = hour.strftime(\"%H:%M\")\n",
    "    print(\"{}: {:.2f} average comments per post\".format(hour, row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the best moment to receive several answers on Hacker News social network is to post an \"ask post\" around 3pm.\n",
    "\n",
    "Be careful ! The time zone used here is Eastern Time in the US. Thus, you need to convert 3pm to the [time zone](https://www.timeanddate.com/time/map/) where you live to take full advantage of this discovery ðŸ˜‰"
   ]
  },
  {
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
